{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11772282,"sourceType":"datasetVersion","datasetId":7390885},{"sourceId":11772333,"sourceType":"datasetVersion","datasetId":7390925}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision transformers pandas pillow python-multipart scikit-learn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-12T03:43:59.159967Z","iopub.execute_input":"2025-05-12T03:43:59.160358Z","iopub.status.idle":"2025-05-12T03:45:08.110488Z","shell.execute_reply.started":"2025-05-12T03:43:59.160305Z","shell.execute_reply":"2025-05-12T03:45:08.109261Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\nRequirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\nUsing cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\nUsing cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\nUsing cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\nUsing cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12\n  Attempting uninstall: nvidia-cusparse-cu12\n\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cublas-cu12\n\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusolver-cu12\n\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: nvidia-cudnn-cu12\n\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom transformers import AutoModel, AutoTokenizer\nfrom torch.optim import AdamW\nimport torchvision\nfrom torchvision import transforms\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T05:26:52.337351Z","iopub.execute_input":"2025-05-12T05:26:52.337574Z","iopub.status.idle":"2025-05-12T05:27:04.286350Z","shell.execute_reply.started":"2025-05-12T05:26:52.337547Z","shell.execute_reply":"2025-05-12T05:27:04.285774Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class MemeDataset(Dataset):\n    def __init__(self, df, base_img_path, tokenizer, max_length, mode='train'):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.mode = mode\n        \n        self.transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n        self.image_paths = []\n        if mode == 'train':\n            for _, row in df.iterrows():\n                folder = 'Hate' if row['label'] == 1 else 'No Hate'\n                self.image_paths.append(os.path.join(base_img_path, folder, row['index']))\n        else:\n            self.image_paths = [os.path.join(base_img_path, fname) for fname in df['index']]\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.image_paths[idx]).convert('RGB')\n        img = self.transform(img)\n\n        text = self.df.iloc[idx]['text']\n        inputs = self.tokenizer(\n            text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n\n        item = {\n            'input_ids': inputs['input_ids'].squeeze(),\n            'attention_mask': inputs['attention_mask'].squeeze(),\n            'image': img,\n            'index': self.df.iloc[idx]['index']\n        }\n\n        if 'label' in self.df.columns:\n            item['label'] = torch.tensor(self.df.iloc[idx]['label'], dtype=torch.long)\n\n        return item\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T05:29:07.149240Z","iopub.execute_input":"2025-05-12T05:29:07.149533Z","iopub.status.idle":"2025-05-12T05:29:07.157542Z","shell.execute_reply.started":"2025-05-12T05:29:07.149512Z","shell.execute_reply":"2025-05-12T05:29:07.156805Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class MultimodalModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.text_encoder = AutoModel.from_pretrained('bert-base-uncased')\n        self.image_encoder = torchvision.models.resnet50(pretrained=True)\n        self.image_encoder = nn.Sequential(*list(self.image_encoder.children())[:-1])\n\n        self.classifier = nn.Sequential(\n            nn.Linear(768 + 2048, 512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, 2)\n        )\n\n    def forward(self, input_ids, attention_mask, image):\n        text_outputs = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n        text_features = text_outputs.last_hidden_state.mean(dim=1)\n\n        image_features = self.image_encoder(image)\n        image_features = image_features.view(image_features.size(0), -1)\n\n        combined = torch.cat([text_features, image_features], dim=1)\n        return self.classifier(combined)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T05:29:09.146464Z","iopub.execute_input":"2025-05-12T05:29:09.146735Z","iopub.status.idle":"2025-05-12T05:29:09.152551Z","shell.execute_reply.started":"2025-05-12T05:29:09.146717Z","shell.execute_reply":"2025-05-12T05:29:09.151894Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"TRAIN_CSV = '/kaggle/input/subtask-a-train/STask_A_train.csv'\nVAL_CSV = '/kaggle/input/subtask-a-eval/STask-A(indextext)val.csv'  # used only for test time\nTRAIN_IMG_DIR = '/kaggle/input/subtask-a-train/Subtask A Train/Subtask A Train'\nVAL_IMG_DIR = '/kaggle/input/subtask-a-eval/Subtask A Eval/STask_A_val_img'\nBATCH_SIZE = 8\nMAX_LEN = 128\nEPOCHS = 5\nLR = 2e-5\n\n# Load labeled training data\nfull_df = pd.read_csv(TRAIN_CSV)\n\n# Split train/val from labeled data\ntrain_df, val_df = train_test_split(full_df, test_size=0.2, stratify=full_df['label'], random_state=42)\n\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\ntrain_dataset = MemeDataset(train_df, TRAIN_IMG_DIR, tokenizer, MAX_LEN, 'train')\nval_dataset = MemeDataset(val_df, TRAIN_IMG_DIR, tokenizer, MAX_LEN, 'train')\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = MultimodalModel().to(device)\noptimizer = AdamW(model.parameters(), lr=LR)\ncriterion = nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T05:29:10.567049Z","iopub.execute_input":"2025-05-12T05:29:10.567294Z","iopub.status.idle":"2025-05-12T05:29:33.292286Z","shell.execute_reply.started":"2025-05-12T05:29:10.567277Z","shell.execute_reply":"2025-05-12T05:29:33.291716Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a9cab560d6d496b8486541424b4a710"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e78c7dc311b4e08b3fda7d89cf288f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8560ac12ad7414c9e774b8b22f421fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5cb7b5b74b842ffbbc963642780d0de"}},"metadata":{}},{"name":"stderr","text":"2025-05-12 05:29:19.709513: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747027759.890638      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747027759.942125      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nXet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a576e8363ee542ada4c8b8c5268165da"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 204MB/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from sklearn.metrics import f1_score, accuracy_score\n\nbest_f1 = 0.0\nsave_path = 'best_multimodal_model.pth'\n\nfor epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\"):\n        optimizer.zero_grad()\n\n        inputs = {\n            'input_ids': batch['input_ids'].to(device),\n            'attention_mask': batch['attention_mask'].to(device),\n            'image': batch['image'].to(device)\n        }\n        labels = batch['label'].to(device)\n\n        outputs = model(**inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"\\nEpoch {epoch+1} | Avg Training Loss: {avg_loss:.4f}\")\n\n    # Validation\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} - Validation\"):\n            inputs = {\n                'input_ids': batch['input_ids'].to(device),\n                'attention_mask': batch['attention_mask'].to(device),\n                'image': batch['image'].to(device)\n            }\n            labels = batch['label'].to(device)\n\n            outputs = model(**inputs)\n            preds = torch.argmax(outputs, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Compute metrics\n    f1 = f1_score(all_labels, all_preds, average='macro')\n    acc = accuracy_score(all_labels, all_preds)\n\n    print(f\"Epoch {epoch+1} | Validation Accuracy: {acc:.4f} | F1 Score: {f1:.4f}\")\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), save_path)\n        print(f\"✅ Best model saved with F1: {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T05:29:36.751169Z","iopub.execute_input":"2025-05-12T05:29:36.752210Z","iopub.status.idle":"2025-05-12T05:53:46.525395Z","shell.execute_reply.started":"2025-05-12T05:29:36.752184Z","shell.execute_reply":"2025-05-12T05:53:46.524735Z"}},"outputs":[{"name":"stderr","text":"Epoch 1 - Training: 100%|██████████| 405/405 [04:36<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 | Avg Training Loss: 0.6358\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 - Validation: 100%|██████████| 102/102 [00:47<00:00,  2.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Validation Accuracy: 0.7136 | F1 Score: 0.7136\n✅ Best model saved with F1: 0.7136\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 - Training: 100%|██████████| 405/405 [04:01<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 | Avg Training Loss: 0.4274\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 - Validation: 100%|██████████| 102/102 [00:38<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Validation Accuracy: 0.6963 | F1 Score: 0.6916\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 - Training: 100%|██████████| 405/405 [04:01<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 | Avg Training Loss: 0.1546\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 - Validation: 100%|██████████| 102/102 [00:38<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Validation Accuracy: 0.7086 | F1 Score: 0.7084\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 - Training: 100%|██████████| 405/405 [04:01<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4 | Avg Training Loss: 0.0803\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 - Validation: 100%|██████████| 102/102 [00:39<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Validation Accuracy: 0.7284 | F1 Score: 0.7284\n✅ Best model saved with F1: 0.7284\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 - Training: 100%|██████████| 405/405 [04:02<00:00,  1.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5 | Avg Training Loss: 0.0443\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 - Validation: 100%|██████████| 102/102 [00:39<00:00,  2.61it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Validation Accuracy: 0.7235 | F1 Score: 0.7232\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Load best model\nmodel.load_state_dict(torch.load('best_multimodal_model.pth'))\nmodel.eval()\n\n# Inference on unlabeled test set\ntest_df = pd.read_csv(VAL_CSV)\ntest_dataset = MemeDataset(test_df, VAL_IMG_DIR, tokenizer, MAX_LEN, mode='eval')\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\npredictions = []\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Final Test Prediction\"):\n        inputs = {\n            'input_ids': batch['input_ids'].to(device),\n            'attention_mask': batch['attention_mask'].to(device),\n            'image': batch['image'].to(device)\n        }\n        outputs = model(**inputs)\n        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n        for idx, pred in zip(batch['index'], preds):\n            predictions.append({'index': idx, 'prediction': int(pred)})\n\n# Save submission\nwith open('submission.json', 'w') as f:\n    for pred in predictions:\n        json.dump(pred, f)\n        f.write('\\n')\n\n!zip -j ref.zip submission.json\nprint(\"✅ Final predictions written to ref.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T05:53:53.916660Z","iopub.execute_input":"2025-05-12T05:53:53.917210Z","iopub.status.idle":"2025-05-12T05:54:23.934661Z","shell.execute_reply.started":"2025-05-12T05:53:53.917183Z","shell.execute_reply":"2025-05-12T05:54:23.933950Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1085669310.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('best_multimodal_model.pth'))\nFinal Test Prediction: 100%|██████████| 64/64 [00:29<00:00,  2.18it/s]","output_type":"stream"},{"name":"stdout","text":"  adding: submission.json (deflated 91%)\n","output_type":"stream"},{"name":"stderr","text":"\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"✅ Final predictions written to ref.zip\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}